import pandas as pd
import os


# === Chargement Excel avec dtypes forc√©s ===
def charger_fichier(fichier):
    return pd.read_excel(fichier, dtype={'Num_parcel': str, 'Num_parcel_2': str, 'Nicad': str})


# === Harmoniser les noms de colonnes ===
def harmoniser_colonnes(df):
    df.columns = df.columns.str.strip()

    if 'Num_parcel_2' in df.columns:
        df['id_parcelle'] = df['Num_parcel_2'].astype(str)
    elif 'Num_parcel' in df.columns:
        df['id_parcelle'] = df['Num_parcel'].astype(str)
    elif 'idup' in df.columns:
        df['id_parcelle'] = df['idup'].astype(str)
    else:
        raise ValueError("Aucune colonne d'identifiant trouv√©e (Num_parcel, Num_parcel_2 ou idup)")

    df = df.rename(columns={
        'communeSenegal': 'commune',
        'nicad': 'hasNicad'  # Renommage pour √©viter la confusion: nicad -> hasNicad
    })

    if 'Village' not in df.columns:
        df['Village'] = "Non sp√©cifi√©"

    # IMPORTANT : Examiner toutes les colonnes potentiellement contenant des NICADs
    nicad_candidates = [col for col in df.columns if 'nicad' in col.lower() or 'nica' in col.lower()]
    if nicad_candidates:
        print(f"   ‚û§ Colonnes potentiellement NICAD trouv√©es: {nicad_candidates}")

    return df


# === Marquer la correspondance URM (NICAD oui/non) ===
def ajouter_nicad(df_kobo, df_urm):
    df_kobo['id_parcelle'] = df_kobo['id_parcelle'].astype(str)
    df_urm['id_parcelle'] = df_urm['id_parcelle'].astype(str)

    # Compter les correspondances pour le d√©bogage
    nb_matches = sum(df_kobo["id_parcelle"].isin(df_urm["id_parcelle"]))
    print(f"   ‚û§ Nombre de correspondances trouv√©es: {nb_matches}")

    # CORRECTION: Renommer pour clarifier - indique si la parcelle a un NICAD
    df_kobo["hasNicad"] = df_kobo["id_parcelle"].isin(df_urm["id_parcelle"]).map({True: "Oui", False: "Non"})

    # IMPORTANT: Essayer d'extraire les vraies valeurs de NICAD depuis df_urm
    if "Nicad" in df_urm.columns:
        # Cr√©er un dictionnaire de mapping id_parcelle -> Nicad
        nicad_mapping = df_urm.set_index('id_parcelle')['Nicad'].to_dict()
        print(f"   ‚û§ Nombre de NICADs dans le mapping: {len(nicad_mapping)}")
        print(f"   ‚û§ Exemples de NICADs du mapping: {list(nicad_mapping.values())[:5]}")

        # Appliquer le mapping pour ajouter les NICADs
        df_kobo['Nicad'] = df_kobo['id_parcelle'].map(nicad_mapping)

        # Compter combien de NICADs ont √©t√© ajout√©s
        nb_nicads_added = df_kobo['Nicad'].notna().sum()
        print(f"   ‚û§ NICADs ajout√©s: {nb_nicads_added}")

    return df_kobo


# === Ajouter les attributs depuis URM avec fallback sur Kobo ===
def completer_attributs(df_kobo, df_urm, attributs, mapping_cols=None):
    if mapping_cols is None:
        mapping_cols = {}
    df_urm_subset = df_urm[['id_parcelle'] + [mapping_cols.get(a, a) for a in attributs if
                                              mapping_cols.get(a, a) in df_urm.columns]].copy()

    # Ajouter Nicad si pr√©sent pour le transfert
    if 'Nicad' in df_urm.columns and 'Nicad' not in attributs:
        df_urm_subset['Nicad'] = df_urm['Nicad']

    df_merge = df_kobo.merge(df_urm_subset, on='id_parcelle', how='left', suffixes=('', '_urm'))

    for attr in attributs:
        col_source = mapping_cols.get(attr, attr)
        col_urm = f"{col_source}_urm"
        if col_urm in df_merge.columns:
            df_merge[attr] = df_merge[col_urm].combine_first(df_merge.get(attr)).fillna("Non sp√©cifi√©")
            df_merge.drop(columns=[col_urm], inplace=True)
        else:
            df_merge[attr] = df_merge.get(attr, "Non sp√©cifi√©").fillna("Non sp√©cifi√©")

    # Transf√©rer √©galement Nicad si disponible
    if 'Nicad_urm' in df_merge.columns:
        df_merge['Nicad'] = df_merge['Nicad_urm'].combine_first(df_merge.get('Nicad')).fillna("")
        df_merge.drop(columns=['Nicad_urm'], inplace=True)

    return df_merge


# === Fonction de normalisation de NICAD ===
def normaliser_nicad(nicad_series):
    if nicad_series is None:
        return None
    # Convertir en string
    nicad_series = nicad_series.astype(str)
    # Enlever les espaces et convertir en majuscules
    nicad_series = nicad_series.str.strip().str.upper()
    # Remplacer les valeurs comme 'nan', 'None', etc.
    nicad_series = nicad_series.replace(['NAN', 'NONE', 'NA', 'N/A', '<NA>', 'NULL', '', '.'], None)
    return nicad_series


# === Afficher des informations de debug sur les NICADs ===
def debug_nicad(df, nom_df):
    print(f"\nüîç Debug NICAD pour {nom_df}:")
    if 'Nicad' in df.columns:
        print(f"   ‚û§ Nombre de NICADs non-null: {df['Nicad'].notna().sum()}")
        print(f"   ‚û§ Exemples de NICADs (premiers 5): {df['Nicad'].dropna().head(5).tolist()}")
    else:
        print(f"   ‚ùå Colonne 'Nicad' absente!")

    # Examiner toutes les colonnes contenant des NICADs potentiels
    nicad_candidates = [col for col in df.columns if 'nicad' in col.lower() or 'nica' in col.lower()]
    for col in nicad_candidates:
        if col != 'Nicad':
            print(f"   ‚û§ Colonne potentielle '{col}': {df[col].notna().sum()} valeurs non-null")
            print(f"   ‚û§ Exemples (premiers 5): {df[col].dropna().head(5).tolist()}")


# === Examiner les colonnes d'un DataFrame ===
def examiner_colonnes(df, nom_df):
    print(f"\nüìã Colonnes de {nom_df}:")
    print(f"   ‚û§ Nombre total de colonnes: {len(df.columns)}")
    print(f"   ‚û§ Liste des colonnes: {df.columns.tolist()}")

    # Extraire quelques statistiques sur les colonnes
    for col in df.columns:
        nb_not_null = df[col].notna().sum()
        pct_not_null = 100 * nb_not_null / len(df) if len(df) > 0 else 0
        print(f"   ‚û§ {col}: {nb_not_null}/{len(df)} valeurs non-null ({pct_not_null:.1f}%)")
        if nb_not_null > 0:
            # Afficher les premi√®res valeurs non-null
            values = df[col].dropna().head(3).tolist()
            print(f"      Exemples: {values}")


try:
    # === Chemins des fichiers ===
    print("üîç Chargement des fichiers source...")
    kobo_individuels = charger_fichier(
        r"C:\Users\ASUS\Downloads\Enquete_Fonci√®re-Parcelles_Individuelles_05052025.xlsx")
    kobo_collectifs = charger_fichier(r"C:\Users\ASUS\Downloads\Enquete_Fonci√®re-Parcelles_Collectives_05052025.xlsx")
    urm_individuels = charger_fichier(
        r"C:\Users\ASUS\Downloads\3.a Validation par URM\3.a Validation par URM\All NICADS\GPKG Merged\parcelles_individuelles_nicad_Lot5_32.xlsx")
    urm_collectifs = charger_fichier(
        r"C:\Users\ASUS\Downloads\3.a Validation par URM\3.a Validation par URM\All NICADS\GPKG Merged\parcelles_collectives_nicad_Lot5_32.xlsx")

    ndoga_init_ind = charger_fichier(
        r"C:\Users\ASUS\Downloads\VALIDATION_NICAD_BND Bon (1)\1.a.Topologie avec jointure (2)\parcelles_individuelles_1234.xlsx")
    ndoga_init_col = charger_fichier(
        r"C:\Users\ASUS\Downloads\VALIDATION_NICAD_BND Bon (1)\1.a.Topologie avec jointure (2)\parcelles_collectives_1234.xlsx")
    ndoga_nicad_ind = charger_fichier(
        r"C:\Users\ASUS\Downloads\VALIDATION_NICAD_BND Bon (1)\VALIDATION_NICAD\Ndoga_Individuelles_NICAD_LOT1_2_3_4.xlsx")
    ndoga_nicad_col = charger_fichier(
        r"C:\Users\ASUS\Downloads\VALIDATION_NICAD_BND Bon (1)\VALIDATION_NICAD\Ndoga_Collectives_NICAD_LOT1_2_3_4.xlsx")

    # === Analyse des structures de fichiers ===
    print("\nüîç Analyse des structures de fichiers pour trouver les NICADs...")
    examiner_colonnes(urm_individuels, "urm_individuels")
    examiner_colonnes(urm_collectifs, "urm_collectifs")
    examiner_colonnes(ndoga_nicad_ind, "ndoga_nicad_ind")
    examiner_colonnes(ndoga_nicad_col, "ndoga_nicad_col")

    # === Harmonisation des colonnes ===
    print("\nüîç Harmonisation des colonnes...")
    df_kobo_ind = harmoniser_colonnes(kobo_individuels)
    df_kobo_col = harmoniser_colonnes(kobo_collectifs)
    df_urm_ind = harmoniser_colonnes(urm_individuels)
    df_urm_col = harmoniser_colonnes(urm_collectifs)
    df_ndoga_init_ind = harmoniser_colonnes(ndoga_init_ind)
    df_ndoga_init_col = harmoniser_colonnes(ndoga_init_col)
    df_ndoga_nicad_ind = harmoniser_colonnes(ndoga_nicad_ind)
    df_ndoga_nicad_col = harmoniser_colonnes(ndoga_nicad_col)

    print("\nüîç Traitement des parcelles individuelles Kobo...")
    df_kobo_ind = ajouter_nicad(df_kobo_ind, df_urm_ind)
    df_kobo_ind = completer_attributs(df_kobo_ind, df_urm_ind, ['superficie', 'type_usag'])
    df_kobo_ind['type_usa'] = "Non applicable"

    print("\nüîç Traitement des parcelles collectives Kobo...")
    df_kobo_col = ajouter_nicad(df_kobo_col, df_urm_col)
    df_kobo_col = completer_attributs(df_kobo_col, df_urm_col, ['superficie', 'type_usa'])
    df_kobo_col['type_usag'] = "Non applicable"

    print("\nüîç Traitement des parcelles individuelles Ndoga...")
    df_ndoga_init_ind = ajouter_nicad(df_ndoga_init_ind, df_ndoga_nicad_ind)
    df_ndoga_init_ind = completer_attributs(
        df_ndoga_init_ind, df_ndoga_nicad_ind,
        ['superficie', 'type_usag'],
        mapping_cols={'type_usag': 'typ_usage'}
    )
    df_ndoga_init_ind['type_usa'] = "Non applicable"

    print("\nüîç Traitement des parcelles collectives Ndoga...")
    df_ndoga_init_col = ajouter_nicad(df_ndoga_init_col, df_ndoga_nicad_col)
    df_ndoga_init_col = completer_attributs(
        df_ndoga_init_col, df_ndoga_nicad_col,
        ['superficie', 'type_usa'],
        mapping_cols={'type_usa': 'typ_usage'}
    )
    df_ndoga_init_col['type_usag'] = "Non applicable"

    # === Fusions ===
    print("\nüîç Fusion des DataFrames...")
    df_kobo_final = pd.concat([df_kobo_ind, df_kobo_col], ignore_index=True)
    df_ndoga_final = pd.concat([df_ndoga_init_ind, df_ndoga_init_col], ignore_index=True)
    df_global_final = pd.concat([df_kobo_final, df_ndoga_final], ignore_index=True)

    # Debug apr√®s fusion
    debug_nicad(df_global_final, "df_global_final apr√®s fusion")

    # === Chargement des d√©lib√©rations avec Nicad et Autorit√© ===
    print("\nüîç Chargement des fichiers de d√©lib√©ration...")
    delib_indiv = pd.read_excel(r"C:\Users\ASUS\Downloads\Deliberation_bandafassi\Delib_Individuel.xlsx",
                                dtype={'Nicad': str})
    delib_collec = pd.read_excel(r"C:\Users\ASUS\Downloads\Deliberation_bandafassi\Delib_Collectif.xlsx",
                                 dtype={'Nicad': str})

    # Afficher les en-t√™tes pour v√©rifier les noms de colonnes
    print(f"Colonnes dans delib_indiv: {delib_indiv.columns.tolist()}")
    print(f"Colonnes dans delib_collec: {delib_collec.columns.tolist()}")

    # Nombre de lignes dans chaque fichier de d√©lib√©ration
    print(f"Nombre d'entr√©es delib_indiv: {len(delib_indiv)}")
    print(f"Nombre d'entr√©es delib_collec: {len(delib_collec)}")

    # Rechercher et afficher explicitement la colonne NICAD
    nicad_col_indiv = [col for col in delib_indiv.columns if 'nicad' in col.lower()]
    nicad_col_collec = [col for col in delib_collec.columns if 'nicad' in col.lower()]
    print(f"Colonnes potentielles pour NICAD dans delib_indiv: {nicad_col_indiv}")
    print(f"Colonnes potentielles pour NICAD dans delib_collec: {nicad_col_collec}")

    # Trouver la colonne d'autorit√©
    autorite_col_indiv = [col for col in delib_indiv.columns if 'autorit' in col.lower() or 'autor' in col.lower()]
    autorite_col_collec = [col for col in delib_collec.columns if 'autorit' in col.lower() or 'autor' in col.lower()]
    print(f"Colonnes potentielles pour Autorit√© dans delib_indiv: {autorite_col_indiv}")
    print(f"Colonnes potentielles pour Autorit√© dans delib_collec: {autorite_col_collec}")

    # Adaptation pour utiliser les bonnes colonnes trouv√©es
    nicad_col_name_indiv = 'Nicad' if 'Nicad' in delib_indiv.columns else (
        nicad_col_indiv[0] if nicad_col_indiv else None)
    nicad_col_name_collec = 'Nicad' if 'Nicad' in delib_collec.columns else (
        nicad_col_collec[0] if nicad_col_collec else None)
    autorite_col_name_indiv = 'Autorit√©' if 'Autorit√©' in delib_indiv.columns else (
        autorite_col_indiv[0] if autorite_col_indiv else None)
    autorite_col_name_collec = 'Autorit√©' if 'Autorit√©' in delib_collec.columns else (
        autorite_col_collec[0] if autorite_col_collec else None)

    # V√©rifier si nous avons trouv√© les colonnes n√©cessaires
    if not nicad_col_name_indiv or not nicad_col_name_collec:
        print("‚ùå ERREUR: Impossible de trouver les colonnes NICAD dans les fichiers de d√©lib√©ration!")

    if not autorite_col_name_indiv or not autorite_col_name_collec:
        print("‚ö†Ô∏è AVERTISSEMENT: Impossible de trouver les colonnes Autorit√© dans les fichiers de d√©lib√©ration.")
        autorite_col_name_indiv = autorite_col_name_indiv or "Autorit√©"  # Valeur par d√©faut
        autorite_col_name_collec = autorite_col_name_collec or "Autorit√©"  # Valeur par d√©faut

    # Renommer les colonnes pour standardisation
    if nicad_col_name_indiv and nicad_col_name_indiv != 'Nicad':
        delib_indiv = delib_indiv.rename(columns={nicad_col_name_indiv: 'Nicad'})
    if nicad_col_name_collec and nicad_col_name_collec != 'Nicad':
        delib_collec = delib_collec.rename(columns={nicad_col_name_collec: 'Nicad'})

    if autorite_col_name_indiv and autorite_col_name_indiv != 'Autorit√©':
        delib_indiv = delib_indiv.rename(columns={autorite_col_name_indiv: 'Autorit√©'})
    if autorite_col_name_collec and autorite_col_name_collec != 'Autorit√©':
        delib_collec = delib_collec.rename(columns={autorite_col_name_collec: 'Autorit√©'})

    # Fusionner les d√©lib√©rations
    delib_global = pd.concat([delib_indiv, delib_collec], ignore_index=True)

    # Debug des NICADs
    debug_nicad(delib_global, "delib_global avant normalisation")
    debug_nicad(df_global_final, "df_global_final avant normalisation")

    # Normaliser les NICADs pour √©viter les probl√®mes de correspondance
    delib_global['Nicad'] = normaliser_nicad(delib_global['Nicad'])
    df_global_final['Nicad'] = normaliser_nicad(df_global_final['Nicad'])

    # Debug apr√®s normalisation
    debug_nicad(delib_global, "delib_global apr√®s normalisation")
    debug_nicad(df_global_final, "df_global_final apr√®s normalisation")

    # V√©rifier les NICADs communs pour d√©bogage
    nicads_delib = set(delib_global['Nicad'].dropna().unique())
    nicads_global = set(df_global_final['Nicad'].dropna().unique())
    nicads_communs = nicads_delib.intersection(nicads_global)
    print(f"\nüß© Analyse NICAD:")
    print(f"   ‚û§ Nombre de NICADs uniques dans les d√©lib√©rations: {len(nicads_delib)}")
    print(f"   ‚û§ Nombre de NICADs uniques dans les parcelles: {len(nicads_global)}")
    print(f"   ‚û§ Nombre de NICADs communs: {len(nicads_communs)}")

    # Liste des NICADs communs (limit√© pour ne pas surcharger la sortie)
    if nicads_communs:
        print(f"   ‚û§ Exemples de NICADs communs: {list(nicads_communs)[:10]}")

    # === CORRECTION: Double m√©thode pour marquer les parcelles d√©lib√©r√©es ===
    print("\nüîç Ajout des informations de d√©lib√©ration...")

    # 1. M√©thode 1: Par jointure sur NICAD (identique √† avant, pour les parcelles avec NICAD)
    delib_subset = delib_global[['Nicad', 'Autorit√©']].dropna(subset=['Nicad']).rename(
        columns={'Autorit√©': 'autorite_delib'}
    )

    # Jointure sur Nicad pour identifier les parcelles d√©lib√©r√©es avec NICAD
    df_merged = df_global_final.merge(
        delib_subset,
        on='Nicad',
        how='left',
        indicator='merge_nicad'
    )

    # Initialiser la colonne 'delibere' avec 'Non' par d√©faut
    df_merged['delibere'] = 'Non'
    # Marquer les parcelles trouv√©es dans la jointure comme 'Oui'
    df_merged.loc[df_merged['merge_nicad'] == 'both', 'delibere'] = 'Oui'

    # 2. M√©thode 2: Marquer √©galement les parcelles ayant hasNicad="Oui" comme d√©lib√©r√©es
    # CORRECTION MAJEURE: Prendre en compte les parcelles avec hasNicad="Oui"
    if 'hasNicad' in df_merged.columns:
        print("   ‚û§ Utilisation de la colonne hasNicad pour les parcelles sans NICAD...")
        # Si pas d√©j√† marqu√© comme d√©lib√©r√© ET a hasNicad="Oui", alors marquer comme d√©lib√©r√©
        df_merged.loc[(df_merged['delibere'] == 'Non') & (df_merged['hasNicad'] == 'Oui'), 'delibere'] = 'Oui'

    # Supprimer la colonne indicatrice temporaire
    if 'merge_nicad' in df_merged.columns:
        df_merged.drop(columns=['merge_nicad'], inplace=True)

    # Remplir les valeurs manquantes d'autorit√©
    if 'autorite_delib' not in df_merged.columns:
        df_merged['autorite_delib'] = "Non sp√©cifi√©"
    else:
        df_merged['autorite_delib'] = df_merged['autorite_delib'].fillna("Non sp√©cifi√©")

    # === Afficher les stats des d√©lib√©rations ===
    parcelles_deliberees = df_merged[df_merged['delibere'] == 'Oui'].shape[0]
    print(f"   ‚û§ Nombre de parcelles d√©lib√©r√©es: {parcelles_deliberees}")

    # Statistiques d√©taill√©es
    parcelles_deliberees_avec_nicad = df_merged[(df_merged['delibere'] == 'Oui') & (df_merged['Nicad'].notna())].shape[
        0]
    parcelles_deliberees_sans_nicad = df_merged[(df_merged['delibere'] == 'Oui') & (df_merged['Nicad'].isna())].shape[0]
    print(f"   ‚û§ Parcelles d√©lib√©r√©es avec NICAD: {parcelles_deliberees_avec_nicad}")
    print(f"   ‚û§ Parcelles d√©lib√©r√©es sans NICAD: {parcelles_deliberees_sans_nicad}")

    # === Colonnes finales √† exporter ===
    colonnes_finales = ["id_parcelle", "commune", "Village", "hasNicad", "superficie", "type_usag", "type_usa",
                        "delibere", "autorite_delib", "Nicad"]

    # Utiliser seulement les colonnes qui existent dans le dataframe
    colonnes_disponibles = [col for col in colonnes_finales if col in df_merged.columns]
    df_export = df_merged[colonnes_disponibles].copy()

    # Cr√©er les dossiers de destination si n√©cessaires
    output_dir = os.path.join(os.getcwd(), "resultat_export")
    os.makedirs(output_dir, exist_ok=True)

    # === Export Excel avec gestion des chemins ===
    # Identifier les lignes de df_kobo_final et df_ndoga_final dans df_merged
    kobo_indices = df_kobo_final.index
    ndoga_indices = df_ndoga_final.index

    # Extraire les sous-ensembles correspondants de df_merged
    df_kobo_export = df_export[df_export.index.isin(kobo_indices)]
    df_ndoga_export = df_export[df_export.index.isin(ndoga_indices)]

    # Chemins de sortie
    kobo_path = os.path.join(output_dir, "parcelles_kobo.xlsx")
    ndoga_path = os.path.join(output_dir, "parcelles_ndoga.xlsx")
    global_path = os.path.join(output_dir, "parcelles_fusionn√©es.xlsx")
    delib_path = os.path.join(output_dir, "parcelles_delib√©r√©es.xlsx")

    # Export avec try/except pour chaque fichier
    try:
        df_kobo_export.to_excel(kobo_path, index=False)
        print(f"‚úÖ Fichier export√©: {kobo_path}")
    except Exception as e:
        print(f"‚ùå √âchec d'export de {kobo_path}: {e}")

    try:
        df_ndoga_export.to_excel(ndoga_path, index=False)
        print(f"‚úÖ Fichier export√©: {ndoga_path}")
    except Exception as e:
        print(f"‚ùå √âchec d'export de {ndoga_path}: {e}")

    try:
        df_export.to_excel(global_path, index=False)
        print(f"‚úÖ Fichier export√©: {global_path}")
    except Exception as e:
        print(f"‚ùå √âchec d'export de {global_path}: {e}")

    try:
        df_export[df_export["delibere"] == "Oui"].to_excel(delib_path, index=False)
        print(f"‚úÖ Fichier export√©: {delib_path}")
    except Exception as e:
        print(f"‚ùå √âchec d'export de {delib_path}: {e}")

    # === R√©sum√© ===
    print("\n‚úÖ Export termin√© !")
    print(f"   ‚û§ parcelles_kobo.xlsx : {len(df_kobo_export)} lignes")
    print(f"   ‚û§ parcelles_ndoga.xlsx : {len(df_ndoga_export)} lignes")
    print(f"   ‚û§ parcelles_fusionn√©es.xlsx : {len(df_export)} lignes")
    print(f"   ‚û§ parcelles_delib√©r√©es.xlsx : {len(df_export[df_export['delibere'] == 'Oui'])} lignes")

    if 'hasNicad' in df_export.columns:
        print(f"   R√©partition NICAD (hasNicad) :\n{df_export['hasNicad'].value_counts().to_string()}")

    print(f"   R√©partition DELIBERE :\n{df_export['delibere'].value_counts().to_string()}")

    # V√©rification finale
    if 'hasNicad' in df_export.columns:
        avec_nicad_delibere = df_export[(df_export['hasNicad'] == 'Oui') & (df_export['delibere'] == 'Oui')].shape[0]
        avec_nicad_non_delibere = df_export[(df_export['hasNicad'] == 'Oui') & (df_export['delibere'] == 'Non')].shape[
            0]
        sans_nicad_delibere = df_export[(df_export['hasNicad'] == 'Non') & (df_export['delibere'] == 'Oui')].shape[0]
        sans_nicad_non_delibere = df_export[(df_export['hasNicad'] == 'Non') & (df_export['delibere'] == 'Non')].shape[
            0]

        print("\nüîç R√©partition d√©taill√©e:")
        print(f"   ‚û§ hasNicad=Oui et delibere=Oui : {avec_nicad_delibere}")
        print(f"   ‚û§ hasNicad=Oui et delibere=Non : {avec_nicad_non_delibere}")
        print(f"   ‚û§ hasNicad=Non et delibere=Oui : {sans_nicad_delibere}")
        print(f"   ‚û§ hasNicad=Non et delibere=Non : {sans_nicad_non_delibere}")

        # Incoh√©rences potentielles
        if avec_nicad_non_delibere > 0:
            print(f"\n‚ö†Ô∏è AVERTISSEMENT: {avec_nicad_non_delibere} parcelles ont un NICAD mais ne sont pas marqu√©es comme d√©lib√©r√©es!")
        if sans_nicad_delibere > 0:
            print(f"\n‚ö†Ô∏è AVERTISSEMENT: {sans_nicad_delibere} parcelles sans NICAD sont marqu√©es comme d√©lib√©r√©es!")

except Exception as e:
    print(f"\n‚ùå ERREUR: {str(e)}")
    import traceback
    traceback.print_exc()